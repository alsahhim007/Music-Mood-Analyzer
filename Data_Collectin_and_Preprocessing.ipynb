{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data collection and preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os, sys\n",
    "\n",
    "# We do this to ignore several specific Pandas warnings\n",
    "import warnings\n",
    "import requests\n",
    "import json\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data from Million Song Subset which is 1.8G in size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dir_tree = '../MillionSongSubset/'\n",
    "\n",
    "for dir_path, dir_names, file_names in os.walk(dir_tree):\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            os.rename(os.path.join(dir_path, file_name), os.path.join(dir_tree, file_name))\n",
    "        except OSError:\n",
    "            print (\"Could not move %s \" % os.join(dir_path, file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build an artist table with file,title, artist columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_artist_table(base):\n",
    "\n",
    "# Get file names\n",
    "\n",
    "    files = [os.path.join(base,fn) for fn in os.listdir(base) if fn.endswith('.h5')]\n",
    "    data = {'file':[], 'artist':[], 'title':[]}\n",
    "\n",
    "    # Add artist and title data to dictionary\n",
    "    for f in files:\n",
    "        store = pd.HDFStore(f)\n",
    "        title = store.root.metadata.songs.cols.title[0]\n",
    "        artist = store.root.metadata.songs.cols.artist_name[0]\n",
    "        data['file'].append(os.path.basename(f))\n",
    "        data['title'].append(title.decode(\"utf-8\"))\n",
    "        data['artist'].append(artist.decode(\"utf-8\"))\n",
    "        store.close()\n",
    "    \n",
    "    # Convert dictionary to pandas DataFrame\n",
    "    df = pd.DataFrame.from_dict(data, orient='columns')\n",
    "    df = df[['file', 'artist', 'title']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '../MillionSongSubset/'\n",
    "df = make_artist_table(base)\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add the lyrics column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lyrics'] = pd.Series('', index=df.index)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download the PyLyrics package to download lyrics from the website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install PyLyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PyLyrics import *\n",
    "## test this function\n",
    "print(PyLyrics.getLyrics('justin bieber','Sorry')) #Print the lyrics directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyprind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyprind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download lyrics with the arguments of artist and track name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "print(df.shape[0])\n",
    "tpbar = pyprind.ProgBar(df.shape[0])\n",
    "for row_id in df.index:\n",
    "    try:\n",
    "        lyr = PyLyrics.getLyrics(df.loc[row_id]['artist'],df.loc[row_id]['title'])    \n",
    "        df.loc[row_id,'lyrics'] = lyr\n",
    "        i+=1\n",
    "        print(i,end=\"\")\n",
    "        pbar.update()\n",
    "    except: #ignore erro when API returns no lyrics \n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('downloaded Lyrics for %s songs' %sum(df.lyrics!=''))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('df_lyr_backup.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop rows that has no lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_lyr_backup.csv')\n",
    "\n",
    "df.head()\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df[df.lyrics!='']\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove songs that is not English song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('words')\n",
    "def eng_ratio(text):\n",
    "    ''' Returns the ratio of non-English to English words from a text '''\n",
    "\n",
    "    english_vocab = set(w.lower() for w in nltk.corpus.words.words())\n",
    "    text_vocab = set(w.lower() for w in text.split() if w.lower().isalpha()) \n",
    "    unusual = text_vocab.difference(english_vocab)\n",
    "    diff = len(unusual)/len(text_vocab)\n",
    "    print(diff)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = df.shape[0]\n",
    "for row_id in df.index:\n",
    "    text = df.loc[row_id]['lyrics']\n",
    "    diff = eng_ratio(text)\n",
    "    if diff >= 0.5:\n",
    "        df = df[df.index != row_id]\n",
    "after = df.shape[0]\n",
    "rem = before - after\n",
    "print('%s have been removed.' %rem)\n",
    "print('%s songs remain in the dataset.' %after)\n",
    "df.to_csv('df_lyr_xyz.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Till now, we got the songs with lyrics, but we have to tag each song with mood. Here I download the tags from Last.fm and classified each some with happy mood or sad mood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv('df_lyr_xyz.csv')\n",
    "\n",
    "df.head()\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSongTags(artist,track):\n",
    "    url = \"http://ws.audioscrobbler.com/2.0/?method=track.getTopTags&api_key=0f6916aff634cb3e768baa9d5ee89341&artist=\"+artist+\"&track=\"+track+\"&format=json\"\n",
    "#     print(url)\n",
    "    results = requests.get(url).json()\n",
    "#     print(results)\n",
    "    tagList = []\n",
    "    if 'toptags' in results:\n",
    "        toptags = results['toptags']\n",
    "        if 'tag' in toptags:\n",
    "            taglistss = toptags['tag']           \n",
    "            for tagItem in taglistss:\n",
    "                tagList.append(tagItem['name']) \n",
    "    return tagList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tags'] = ''\n",
    "pbar = pyprind.ProgBar(df.shape[0])\n",
    "i=0\n",
    "for row_id in df.index:\n",
    "    print(i, end=\" \")\n",
    "    i+=1\n",
    "    tags = getSongTags(df.loc[row_id]['artist'],df.loc[row_id]['title'])  \n",
    "    df.loc[row_id,'tags'] = tags\n",
    "    pbar.update()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSongTags(\"The Weeknd\",\"Call Out My Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[1,'tags']\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row_id in df.index:     \n",
    "    if len(df.loc[row_id,'tags']) == 2:\n",
    "        df = df.drop(row_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.Series('', index=df.index)\n",
    "\n",
    "base = '../MillionSongSubset/'\n",
    "files = [os.path.join(base,fn) for fn in os.listdir(base) if fn.endswith('.h5')]\n",
    "for row_id in df.index:\n",
    "    filename = df.loc[row_id]['file']\n",
    "    filepath = os.path.join(base,filename)\n",
    "    store = pd.HDFStore(filepath)\n",
    "    year = store.root.musicbrainz.songs.cols.year[0]\n",
    "    print(year)\n",
    "    df.loc[row_id]['year'] = year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"image.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataset_year.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Happy or Sad\n",
    "### Group id\tTags\tnum. of tags\tnum. of songs\n",
    "#### sad tags:\n",
    "\n",
    "G15\tsad, sadness, unhappy, melancholic, melancholy, feeling sad, mood: sad - slightly, sad song\t8\t1,178\n",
    "\n",
    "G16\tdepressed, blue, dark, depressive, dreary, gloom, darkness, depress, depression, depressing, gloomy\t11\t471\n",
    "\n",
    "G28\tanger, angry, choleric, fury, outraged, rage, angry music\t7\t254\n",
    "\n",
    "G17\tgrief, heartbreak, mournful, sorrow, sorry, doleful, heartache, heartbreaking, heartsick, lachrymose, mourning, plaintive, regret, sorrowful\t14\t183\n",
    "\n",
    "#### happy tags:\n",
    "G6\tcheerful, cheer up, festive, jolly, jovial, merry, cheer, cheering, cheery, get happy, rejoice, songs that are cheerful, sunny\t13\t142\n",
    "\n",
    "G5\thappy, happiness, happy songs, happy music, glad, mood: happy\t6\t749\n",
    "\n",
    "G2\tupbeat, gleeful, high spirits, zest, enthusiastic, buoyancy, elation, mood: upbeat\t8\t543\n",
    "\n",
    "G1\texcitement, exciting, exhilarating, thrill, ardor, stimulating, thrilling, titillating\t8\t30\n",
    "TOTAL\t\t135\t6,490\n",
    "\n",
    "### This tag summary comes from the last.fm website which were group into different categories. Here, I choose group 15,16,28,17 as sad tag and group 5,6,2,1 as happy songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happyTags = \"cheerful, cheer up, festive, jolly, jovial, merry, cheer, cheering,\\\n",
    "cheery, get happy, rejoice, songs that are cheerful, sunny,happy, happiness, happy songs, happy music, glad, mood: happy,\\\n",
    "upbeat, gleeful, high spirits, zest, enthusiastic, buoyancy, elation, mood: upbeat,excitement, exciting, exhilarating, thrill,\\\n",
    "ardor, stimulating, thrilling, titillating\"\n",
    "happyTags = happyTags.replace(\" \",\"\").split(\",\")\n",
    "\n",
    "sagTags = \"sad, sadness, unhappy, melancholic, melancholy, feeling sad, mood: sad - slightly, sad song,\\\n",
    "depressed, blue, dark, depressive, dreary, gloom, darkness, depress, depression, depressing, gloomy,\\\n",
    "anger, angry, choleric, fury, outraged, rage, angry music,grief, heartbreak, mournful, sorrow, sorry, doleful, heartache, heartbreaking, heartsick, lachrymose, mourning,\\\n",
    "plaintive, regret, sorrowful\"\n",
    "sagTags = sagTags.replace(\" \",\"\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "happyTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagTags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the tag numbers from sad group or the happy group, we can assign a mood value 1(happy) or 0(sad) to the mood column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abcd=df.loc[1,'tags'].replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\" \",\"\").split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(abcd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mood']=\"\"\n",
    "pbar = pyprind.ProgBar(df.shape[0])\n",
    "for row_id in df.index:\n",
    "#     tags = df.loc[row_id,'tags']    \n",
    "    tags = df.loc[row_id,'tags'].replace(\"[\",\"\").replace(\"]\",\"\").replace(\"'\",\"\").replace(\" \",\"\").split(\",\")   \n",
    "    sad_tags = np.intersect1d(tags,sagTags) \n",
    "    happy_tags = np.intersect1d(tags,happyTags)\n",
    "    if len(sad_tags)>0 or len(happy_tags)>0:# having mood tag\n",
    "        if len(sad_tags)>len(happy_tags):\n",
    "            df.loc[row_id,'mood'] = 0\n",
    "        else:\n",
    "            df.loc[row_id,'mood'] = 1\n",
    "    else:\n",
    "        df = df.drop(row_id)# remove songs that does not have tag\n",
    "    pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"mood.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = pd.Series('', index=df.index)\n",
    "\n",
    "base = '../MillionSongSubset/'\n",
    "files = [os.path.join(base,fn) for fn in os.listdir(base) if fn.endswith('.h5')]\n",
    "for row_id in df.index:\n",
    "    filename = df.loc[row_id]['file']\n",
    "    filepath = os.path.join(base,filename)\n",
    "    store = pd.HDFStore(filepath)\n",
    "    year = store.root.musicbrainz.songs.cols.year[0]\n",
    "    df.loc[row_id]['year'] = year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dataset_lyrics.csv', index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(\"tags\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df.mood==1])/166\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save songs with mood tag into csv file for training and keywords extraction\n",
    "df.to_csv('dataset_lyrics.csv', index=False,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Dataset_tags.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
